{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file tokenizer.json from cache at /home/jeromeku/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B/snapshots/4e20de362430cd3b72f300e6b0f18e50e7166e08/tokenizer.json\n",
      "loading file tokenizer.model from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/jeromeku/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B/snapshots/4e20de362430cd3b72f300e6b0f18e50e7166e08/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/jeromeku/.cache/huggingface/hub/models--meta-llama--Llama-3.2-1B/snapshots/4e20de362430cd3b72f300e6b0f18e50e7166e08/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers.utils.logging import set_verbosity_debug\n",
    "\n",
    "set_verbosity_debug()\n",
    "\n",
    "MODEL_ID = \"meta-llama/Llama-3.2-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer(version=\"1.0\", truncation=None, padding=None, added_tokens=[{\"id\":128000, \"content\":\"<|begin_of_text|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128001, \"content\":\"<|end_of_text|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128002, \"content\":\"<|reserved_special_token_0|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128003, \"content\":\"<|reserved_special_token_1|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128004, \"content\":\"<|finetune_right_pad_id|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128005, \"content\":\"<|reserved_special_token_2|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128006, \"content\":\"<|start_header_id|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128007, \"content\":\"<|end_header_id|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128008, \"content\":\"<|eom_id|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128009, \"content\":\"<|eot_id|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128010, \"content\":\"<|python_tag|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128011, \"content\":\"<|reserved_special_token_3|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128012, \"content\":\"<|reserved_special_token_4|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128013, \"content\":\"<|reserved_special_token_5|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128014, \"content\":\"<|reserved_special_token_6|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128015, \"content\":\"<|reserved_special_token_7|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128016, \"content\":\"<|reserved_special_token_8|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128017, \"content\":\"<|reserved_special_token_9|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128018, \"content\":\"<|reserved_special_token_10|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128019, \"content\":\"<|reserved_special_token_11|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128020, \"content\":\"<|reserved_special_token_12|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128021, \"content\":\"<|reserved_special_token_13|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128022, \"content\":\"<|reserved_special_token_14|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128023, \"content\":\"<|reserved_special_token_15|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128024, \"content\":\"<|reserved_special_token_16|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128025, \"content\":\"<|reserved_special_token_17|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128026, \"content\":\"<|reserved_special_token_18|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128027, \"content\":\"<|reserved_special_token_19|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128028, \"content\":\"<|reserved_special_token_20|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128029, \"content\":\"<|reserved_special_token_21|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128030, \"content\":\"<|reserved_special_token_22|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128031, \"content\":\"<|reserved_special_token_23|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128032, \"content\":\"<|reserved_special_token_24|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128033, \"content\":\"<|reserved_special_token_25|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128034, \"content\":\"<|reserved_special_token_26|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128035, \"content\":\"<|reserved_special_token_27|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128036, \"content\":\"<|reserved_special_token_28|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128037, \"content\":\"<|reserved_special_token_29|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128038, \"content\":\"<|reserved_special_token_30|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128039, \"content\":\"<|reserved_special_token_31|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128040, \"content\":\"<|reserved_special_token_32|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128041, \"content\":\"<|reserved_special_token_33|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128042, \"content\":\"<|reserved_special_token_34|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128043, \"content\":\"<|reserved_special_token_35|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128044, \"content\":\"<|reserved_special_token_36|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128045, \"content\":\"<|reserved_special_token_37|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128046, \"content\":\"<|reserved_special_token_38|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128047, \"content\":\"<|reserved_special_token_39|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128048, \"content\":\"<|reserved_special_token_40|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128049, \"content\":\"<|reserved_special_token_41|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128050, \"content\":\"<|reserved_special_token_42|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128051, \"content\":\"<|reserved_special_token_43|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128052, \"content\":\"<|reserved_special_token_44|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128053, \"content\":\"<|reserved_special_token_45|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128054, \"content\":\"<|reserved_special_token_46|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128055, \"content\":\"<|reserved_special_token_47|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128056, \"content\":\"<|reserved_special_token_48|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128057, \"content\":\"<|reserved_special_token_49|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128058, \"content\":\"<|reserved_special_token_50|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128059, \"content\":\"<|reserved_special_token_51|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128060, \"content\":\"<|reserved_special_token_52|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128061, \"content\":\"<|reserved_special_token_53|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128062, \"content\":\"<|reserved_special_token_54|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128063, \"content\":\"<|reserved_special_token_55|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128064, \"content\":\"<|reserved_special_token_56|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128065, \"content\":\"<|reserved_special_token_57|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128066, \"content\":\"<|reserved_special_token_58|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128067, \"content\":\"<|reserved_special_token_59|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128068, \"content\":\"<|reserved_special_token_60|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128069, \"content\":\"<|reserved_special_token_61|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128070, \"content\":\"<|reserved_special_token_62|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128071, \"content\":\"<|reserved_special_token_63|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128072, \"content\":\"<|reserved_special_token_64|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128073, \"content\":\"<|reserved_special_token_65|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128074, \"content\":\"<|reserved_special_token_66|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128075, \"content\":\"<|reserved_special_token_67|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128076, \"content\":\"<|reserved_special_token_68|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128077, \"content\":\"<|reserved_special_token_69|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128078, \"content\":\"<|reserved_special_token_70|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128079, \"content\":\"<|reserved_special_token_71|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128080, \"content\":\"<|reserved_special_token_72|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128081, \"content\":\"<|reserved_special_token_73|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128082, \"content\":\"<|reserved_special_token_74|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128083, \"content\":\"<|reserved_special_token_75|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128084, \"content\":\"<|reserved_special_token_76|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128085, \"content\":\"<|reserved_special_token_77|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128086, \"content\":\"<|reserved_special_token_78|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128087, \"content\":\"<|reserved_special_token_79|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128088, \"content\":\"<|reserved_special_token_80|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128089, \"content\":\"<|reserved_special_token_81|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128090, \"content\":\"<|reserved_special_token_82|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128091, \"content\":\"<|reserved_special_token_83|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128092, \"content\":\"<|reserved_special_token_84|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128093, \"content\":\"<|reserved_special_token_85|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128094, \"content\":\"<|reserved_special_token_86|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128095, \"content\":\"<|reserved_special_token_87|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128096, \"content\":\"<|reserved_special_token_88|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128097, \"content\":\"<|reserved_special_token_89|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, {\"id\":128098, \"content\":\"<|reserved_special_token_90|>\", \"single_word\":False, \"lstrip\":False, \"rstrip\":False, \"normalized\":False, \"special\":True}, ...], normalizer=None, pre_tokenizer=Sequence(pretokenizers=[Split(pattern=Regex(\"(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+\"), behavior=Isolated, invert=False), ByteLevel(add_prefix_space=False, trim_offsets=True, use_regex=False)]), post_processor=Sequence(processors=[ByteLevel(add_prefix_space=True, trim_offsets=False, use_regex=True), TemplateProcessing(single=[SpecialToken(id=\"<|begin_of_text|>\", type_id=0), Sequence(id=A, type_id=0)], pair=[SpecialToken(id=\"<|begin_of_text|>\", type_id=0), Sequence(id=A, type_id=0), SpecialToken(id=\"<|begin_of_text|>\", type_id=1), Sequence(id=B, type_id=1)], special_tokens={\"<|begin_of_text|>\":SpecialToken(id=\"<|begin_of_text|>\", ids=[128000], tokens=[\"<|begin_of_text|>\"])})]), decoder=ByteLevel(add_prefix_space=True, trim_offsets=True, use_regex=True), model=BPE(dropout=None, unk_token=None, continuing_subword_prefix=None, end_of_word_suffix=None, fuse_unk=False, byte_fallback=False, ignore_merges=True, vocab={\"!\":0, \"\"\":1, \"#\":2, \"$\":3, \"%\":4, \"&\":5, \"'\":6, \"(\":7, \")\":8, \"*\":9, \"+\":10, \",\":11, \"-\":12, \".\":13, \"/\":14, \"0\":15, \"1\":16, \"2\":17, \"3\":18, \"4\":19, \"5\":20, \"6\":21, \"7\":22, \"8\":23, \"9\":24, \":\":25, \";\":26, \"<\":27, \"=\":28, \">\":29, \"?\":30, \"@\":31, \"A\":32, \"B\":33, \"C\":34, \"D\":35, \"E\":36, \"F\":37, \"G\":38, \"H\":39, \"I\":40, \"J\":41, \"K\":42, \"L\":43, \"M\":44, \"N\":45, \"O\":46, \"P\":47, \"Q\":48, \"R\":49, \"S\":50, \"T\":51, \"U\":52, \"V\":53, \"W\":54, \"X\":55, \"Y\":56, \"Z\":57, \"[\":58, \"\\\":59, \"]\":60, \"^\":61, \"_\":62, \"`\":63, \"a\":64, \"b\":65, \"c\":66, \"d\":67, \"e\":68, \"f\":69, \"g\":70, \"h\":71, \"i\":72, \"j\":73, \"k\":74, \"l\":75, \"m\":76, \"n\":77, \"o\":78, \"p\":79, \"q\":80, \"r\":81, \"s\":82, \"t\":83, \"u\":84, \"v\":85, \"w\":86, \"x\":87, \"y\":88, \"z\":89, \"{\":90, \"|\":91, \"}\":92, \"~\":93, \"¡\":94, \"¢\":95, \"£\":96, \"¤\":97, \"¥\":98, ...}, merges=[(\"Ġ\", \"Ġ\"), (\"Ġ\", \"ĠĠĠ\"), (\"ĠĠ\", \"ĠĠ\"), (\"ĠĠĠ\", \"Ġ\"), (\"i\", \"n\"), (\"Ġ\", \"t\"), (\"Ġ\", \"ĠĠĠĠĠĠĠ\"), (\"ĠĠ\", \"ĠĠĠĠĠĠ\"), (\"ĠĠĠĠ\", \"ĠĠĠĠ\"), (\"ĠĠĠ\", \"ĠĠĠĠĠ\"), (\"ĠĠĠĠĠĠĠ\", \"Ġ\"), (\"ĠĠĠĠĠ\", \"ĠĠĠ\"), (\"ĠĠĠĠĠĠ\", \"ĠĠ\"), (\"e\", \"r\"), (\"Ġ\", \"ĠĠ\"), (\"ĠĠ\", \"Ġ\"), (\"o\", \"n\"), (\"Ġ\", \"a\"), (\"r\", \"e\"), (\"a\", \"t\"), (\"s\", \"t\"), (\"e\", \"n\"), (\"o\", \"r\"), (\"Ġ\", \"th\"), (\"Ġt\", \"h\"), (\"Ċ\", \"Ċ\"), (\"Ġ\", \"c\"), (\"l\", \"e\"), (\"Ġ\", \"s\"), (\"i\", \"t\"), (\"a\", \"n\"), (\"a\", \"r\"), (\"a\", \"l\"), (\"Ġ\", \"the\"), (\"Ġt\", \"he\"), (\"Ġth\", \"e\"), (\";\", \"Ċ\"), (\"Ġ\", \"p\"), (\"Ġ\", \"f\"), (\"o\", \"u\"), (\"Ġ\", \"=\"), (\"i\", \"s\"), (\"Ġ\", \"ĠĠĠĠĠĠ\"), (\"ĠĠ\", \"ĠĠĠĠĠ\"), (\"ĠĠĠĠ\", \"ĠĠĠ\"), (\"ĠĠĠ\", \"ĠĠĠĠ\"), (\"ĠĠĠĠĠ\", \"ĠĠ\"), (\"ĠĠĠĠĠĠ\", \"Ġ\"), (\"i\", \"ng\"), (\"in\", \"g\"), (\"e\", \"s\"), (\"Ġ\", \"w\"), (\"i\", \"on\"), (\"io\", \"n\"), (\"e\", \"d\"), (\"i\", \"c\"), (\"Ġ\", \"b\"), (\"Ġ\", \"d\"), (\"e\", \"t\"), (\"Ġ\", \"m\"), (\"Ġ\", \"o\"), (\"ĉ\", \"ĉ\"), (\"r\", \"o\"), (\"a\", \"s\"), (\"e\", \"l\"), (\"c\", \"t\"), (\"n\", \"d\"), (\"Ġ\", \"in\"), (\"Ġi\", \"n\"), (\"Ġ\", \"h\"), (\"e\", \"nt\"), (\"en\", \"t\"), (\"i\", \"d\"), (\"Ġ\", \"n\"), (\"a\", \"m\"), (\"Ġ\", \"ĠĠĠĠĠĠĠĠĠĠ\"), (\"ĠĠ\", \"ĠĠĠĠĠĠĠĠĠ\"), (\"ĠĠĠĠ\", \"ĠĠĠĠĠĠĠ\"), (\"ĠĠĠĠĠĠĠĠ\", \"ĠĠĠ\"), (\"ĠĠĠ\", \"ĠĠĠĠĠĠĠĠ\"), (\"ĠĠĠĠĠĠĠ\", \"ĠĠĠĠ\"), (\"ĠĠĠĠĠ\", \"ĠĠĠĠĠĠ\"), (\"ĠĠĠĠĠĠĠĠĠ\", \"ĠĠ\"), (\"ĠĠĠĠĠĠ\", \"ĠĠĠĠĠ\"), (\"ĠĠĠĠĠĠĠĠĠĠ\", \"Ġ\"), (\"Ġ\", \"to\"), (\"Ġt\", \"o\"), (\"Ġ\", \"re\"), (\"Ġr\", \"e\"), (\"-\", \"-\"), (\"Ġ\", \"{\"), (\"Ġ\", \"of\"), (\"Ġo\", \"f\"), (\"o\", \"m\"), (\")\", \";Ċ\"), (\");\", \"Ċ\"), (\"i\", \"m\"), (\"č\", \"Ċ\"), (\"Ġ\", \"(\"), ...]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer._tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_vocab = tokenizer.get_added_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(added_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m texts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, world!\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMy name is Jerome\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3150\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3133\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3134\u001b[0m \u001b[38;5;124;03mTokenize and prepare for the model a list of sequences or a list of pairs of sequences.\u001b[39;00m\n\u001b[1;32m   3135\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3146\u001b[0m \u001b[38;5;124;03m        details in `encode_plus`).\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3149\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m-> 3150\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_padding_truncation_strategies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3156\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3157\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[1;32m   3160\u001b[0m     batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   3161\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3178\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3179\u001b[0m )\n",
      "File \u001b[0;32m~/dev/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2771\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._get_padding_truncation_strategies\u001b[0;34m(self, padding, truncation, max_length, pad_to_multiple_of, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2769\u001b[0m \u001b[38;5;66;03m# Test if we have a padding token\u001b[39;00m\n\u001b[1;32m   2770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding_strategy \u001b[38;5;241m!=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m-> 2771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2772\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsking to pad but the tokenizer does not have a padding token. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2773\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2774\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor add a new pad token via `tokenizer.add_special_tokens(\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad_token\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[PAD]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m})`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2775\u001b[0m     )\n\u001b[1;32m   2777\u001b[0m \u001b[38;5;66;03m# Check that we will truncate to a multiple of pad_to_multiple_of if both are provided\u001b[39;00m\n\u001b[1;32m   2778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2779\u001b[0m     truncation_strategy \u001b[38;5;241m!=\u001b[39m TruncationStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_TRUNCATE\n\u001b[1;32m   2780\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m padding_strategy \u001b[38;5;241m!=\u001b[39m PaddingStrategy\u001b[38;5;241m.\u001b[39mDO_NOT_PAD\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2783\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (max_length \u001b[38;5;241m%\u001b[39m pad_to_multiple_of \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2784\u001b[0m ):\n",
      "\u001b[0;31mValueError\u001b[0m: Asking to pad but the tokenizer does not have a padding token. Please select a token to use as `pad_token` `(tokenizer.pad_token = tokenizer.eos_token e.g.)` or add a new pad token via `tokenizer.add_special_tokens({'pad_token': '[PAD]'})`."
     ]
    }
   ],
   "source": [
    "texts = [\"Hello, world!\", \"My name is Jerome\"]\n",
    "tokenizer.batch_encode_plus(texts, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128256"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_vocab = tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128257"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
